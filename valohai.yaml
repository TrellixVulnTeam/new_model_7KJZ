---
- step:
    name: Convert Mask to GrayScale
    description: Converts Mask Images to Grayscale
    image: tensorflow/tensorflow:1.15.4-gpu-py3
    command:
        - apt-get update
        - apt-get install ffmpeg libsm6 libxext6 -y
        - pip install opencv-python
        - python research/deeplab/mask_to_grayscale.py
    inputs:
      - name: RGB-Masks-folder
        default: azure://sampledata/rgbmasksfolder/*
        keep-directories: suffix
      - name: class-index-file
        default: azure://sampledata/
      - name: metadata-filepath
        default: azure://sampledata/
- step:
    name: Load data and convert
    description: Converts data to TFRecord file format with Example protos
    image: tensorflow/tensorflow:1.15.4-gpu-py3
    command:
        - python research/deeplab/datasets/build_voc2012_data.py
    inputs:
      - name: Label-Folder
        default: azure://sampledata/rgbmasksfolder/*
        keep-directories: suffix
      - name: Image-Folder
        default: azure://sampledata/JpgImage/*
        keep-directories: suffix
      - name: Split-Folder
        default: azure://sampledata/Splitfolder/*
        keep-directories: suffix
- step:
    name: Train DeepLab model
    image: tensorflow/tensorflow:1.15.4-gpu-py3
    command:
        - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/research/slim:`pwd`/research
        - pip install -r requirements.txt
        - unzip /valohai/inputs/tfrecords/tfrecords.zip -d /valohai/inputs/tfrecords
        - python research/deeplab/train.py --atrous_rates=6 --atrous_rates=12 --atrous_rates=18 {parameters}
    inputs:
      - name: tfrecords
        default: azure://tcsvalohai/deeplab/data/01ERE/01EREM82KQF8DNWGJT3GNM3Q35/upload/tfrecords.zip
    parameters:
      - name: logtostderr
        type: flag
        default: True
        pass-as: --logtostderr={v}
      - name: training_number_of_steps
        type: integer
        default: 150000
        description: "The number of steps used for training"
      - name: train_split
        type: string
        default: "train"
        description: "Which split of the dataset to be used for training"
      - name: model_variant
        type: string
        default: "xception_65"
      - name: output_stride
        type: integer
        default: 16
      - name: decoder_output_stride
        type: integer
        default: 4
      - name: train_crop_size
        type: string
        default: "513,513"
        description: "Image crop size [height, width] during training."
      - name: train_batch_size
        type: integer
        default: 4
        description: "The number of images in each batch during training."
      - name: min_resize_value
        type: integer
        default: 513
      - name: max_resize_value
        type: integer
        default: 513
      - name: resize_factor
        type: integer
        default: 16
      - name: dataset
        type: string
        default: "pascal_voc_seg"
        description: "Name of the segmentation dataset."
      - name: train_logdir
        type: string
        default: "/valohai/repository/trainlog/"
- step:
    name: Save Frozen Graph
    description: Converts model checkpoints to frozen graph
    image: tensorflow/tensorflow:1.15.4-gpu-py3
    command:
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/research/slim:`pwd`/research
      - pip install -r requirements.txt
      - mkdir /valohai/outputs/Logs
      - mkdir trainlog
      - tar -xvzf /valohai/inputs/checkpoint-path/checkpoints.tar.gz -C /valohai/repository/trainlog/
      - python research/deeplab/export_model.py {parameters}
    inputs:
      - name: checkpoint-path
        default: azure://sampledatavalohai/sampledata/data/01EY5/01EY5YHQYRT70D8Q390Q4A0K2B/output-79/checkpoints.tar.gz
    parameters:
      - name: logtostderr
        type: flag
        default: True
        pass-as: --logtostderr={v}
      - name: model_variant
        type: string
        default: "xception_65"
      - name: output_stride
        type: integer
        default: 16
      - name: decoder_output_stride
        type: integer
        default: 4
      - name: crop_size
        type: string
        default: 513,513
        description: "Image crop size [height, width]"
      - name: num_classes
        type: integer
        default: 3
      - name: export_path
        type: string
        default: /valohai/outputs/frozen_inference_graph.pb
- pipeline:
    name: TCSSample
    nodes:
      - name: convert-node
        type: execution
        step: Convert Mask to GrayScale
      - name: load-node
        type: execution
        step: Load data and convert
        override:
          inputs:
            - name: Label-Folder
      - name: train-node
        type: execution
        step: Train DeepLab model
        override:
          inputs:
            - name: tfrecords
      - name: save-node
        type: execution
        step: Save Frozen Graph
        override: 
          inputs:
            - name: checkpoint-path
    edges:
      - [convert-node.output.Output-Directory/*, load-node.input.Label-Folder]
      - [load-node.output.tfrecords.zip, train-node.input.tfrecords]
      - [train-node.output.*, save-node.input.checkpoint-path]
